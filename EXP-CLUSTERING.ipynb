{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data=pd.read_excel('C:/Users/dps/Desktop/data/data.xlsx') #Include your data file instead of data.xlsx\n",
    "idea=data.iloc[:,0:1] #Selecting the first column that has text.\n",
    "\n",
    "#corpus=[]\n",
    "#for index,row in idea.iterrows():\n",
    "#    corpus.append(row['Idea']\n",
    "                  \n",
    "#Converting the column of data from excel sheet into a list of documents, where each document corresponds to a group of sentences.\n",
    "corpus=['She went to the airport to see him off.','I prefer reading to writing.',\n",
    "        'Los Angeles is in California. It is southeast of San Francisco.'\n",
    "        ,'I ate a burger then went to bed.','Compare your answer with Tom.',\n",
    "        'I had hardly left home when it began to rain heavily.',\n",
    "        'If he had asked me, I would have given it to him. ',\n",
    "        'I could have come by auto, but who would pay the fare? ',\n",
    "        'Whatever it may be, you should not have beaten him.',\n",
    "        'You should have told me yesterday','I should have joined this course last year.',\n",
    "        'Where are you going?','There are too many people here.','Everyone always asks me that.',       \n",
    "        'I did not think you were going to make it.','Be quiet while I am speaking.','I can not figure out why he said so.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airport', 'always', 'am', 'angeles', 'answer', 'are', 'asked', 'asks', 'ate', 'auto', 'be', 'beaten', 'bed', 'began', 'burger', 'but', 'by', 'california', 'can', 'come', 'compare', 'could', 'course', 'did', 'everyone', 'fare', 'figure', 'francisco', 'given', 'going', 'had', 'hardly', 'have', 'he', 'heavily', 'here', 'him', 'home', 'if', 'in', 'is', 'it', 'joined', 'last', 'left', 'los', 'make', 'many', 'may', 'me', 'not', 'of', 'off', 'out', 'pay', 'people', 'prefer', 'quiet', 'rain', 'reading', 'said', 'san', 'see', 'she', 'should', 'so', 'southeast', 'speaking', 'that', 'the', 'then', 'there', 'think', 'this', 'to', 'told', 'tom', 'too', 'went', 'were', 'whatever', 'when', 'where', 'while', 'who', 'why', 'with', 'would', 'writing', 'year', 'yesterday', 'you', 'your']\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Count Vectoriser then tidf transformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 93)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37835527 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.25620815 0.        ]\n",
      " [0.         0.         0.46269305 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "print(tfidf.toarray())                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                                Idea  Cluster\n",
      "1            She went to the airport to see him off.        1\n",
      "1                       I prefer reading to writing.        1\n",
      "0  Los Angeles is in California. It is southeast ...        0\n",
      "1                   I ate a burger then went to bed.        1\n",
      "2                      Compare your answer with Tom.        2\n",
      "0  I had hardly left home when it began to rain h...        0\n",
      "2  If he had asked me, I would have given it to h...        2\n",
      "2  I could have come by auto, but who would pay t...        2\n",
      "2  Whatever it may be, you should not have beaten...        2\n",
      "2                  You should have told me yesterday        2\n",
      "2        I should have joined this course last year.        2\n",
      "0                               Where are you going?        0\n",
      "0                    There are too many people here.        0\n",
      "2                      Everyone always asks me that.        2\n",
      "0         I did not think you were going to make it.        0\n",
      "2                      Be quiet while I am speaking.        2\n",
      "0               I can not figure out why he said so.        0\n",
      "\n",
      "\n",
      "2    8\n",
      "0    6\n",
      "1    3\n",
      "Name: Cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 3 #Change it according to your data.\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf)\n",
    "clusters = km.labels_.tolist()\n",
    "idea={'Idea':corpus, 'Cluster':clusters} #Creating dict having doc with the corresponding cluster number.\n",
    "frame=pd.DataFrame(idea,index=[clusters], columns=['Idea','Cluster']) # Converting it into a dataframe.\n",
    "\n",
    "print(\"\\n\")\n",
    "print(frame) #Print the doc with the labeled cluster number.\n",
    "print(\"\\n\")\n",
    "print(frame['Cluster'].value_counts()) #Print the counts of doc belonging to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
